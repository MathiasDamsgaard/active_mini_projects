{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import random\n",
    "np.random.seed(32)\n",
    "random.seed(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the MNIST Fashion dataset\n",
    "filename = 'fashion-mnist.csv'\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "X = df.iloc[:, 1:].values\n",
    "y = df.iloc[:, 0].values\n",
    "\n",
    "# Normalize pixel values between [0, 1]\n",
    "X = X / 255\n",
    "\n",
    "# Only use 50% of data\n",
    "rand = random.sample(range(10000), 5000)\n",
    "X = X[rand]\n",
    "y = y[rand]\n",
    "\n",
    "# One-hot encoding\n",
    "y = to_categorical(y)\n",
    "\n",
    "# Split the dataset into training and test data sets\n",
    "X_left, X_gen, y_left, y_gen = train_test_split(X, y, test_size=0.2, random_state=420)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_left, y_left, test_size=0.25, random_state=420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "def create_model(learning_rate, dropout_rate, num_filters, num_layers):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(num_filters, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    for i in range(num_layers):\n",
    "        model.add(Conv2D(num_filters, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate = learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the search space for the hyperparameters\n",
    "search_space = [Real(1e-4, 1e-2, name='learning_rate'),\n",
    "                Real(0.1, 0.5, name='dropout_rate'),\n",
    "                Integer(16, 64, name='num_filters'),\n",
    "                Integer(1, 3, name='num_layers')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the objective function to minimize (i.e., 1 - accuracy)\n",
    "acc_list = []\n",
    "\n",
    "@use_named_args(search_space)\n",
    "def objective(**params):\n",
    "    # Create the model\n",
    "    model = create_model(**params)\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train.reshape(-1, 28, 28, 1), y_train, epochs=10, verbose=0)\n",
    "\n",
    "    # Predict the labels for the test data\n",
    "    y_pred = model.predict(X_test.reshape(-1, 28, 28, 1))\n",
    "\n",
    "    # Convert the predicted labels to integers\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Compute the accuracy of the model\n",
    "    accuracy = accuracy_score(np.argmax(y_test, axis=1), y_pred)\n",
    "\n",
    "    #print(accuracy)\n",
    "    acc_list.append(accuracy)\n",
    "\n",
    "    # Return 1 - accuracy (to minimize)\n",
    "    return 1.0 - accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "One of the dimensions in the output is <= 0 due to downsampling in conv2d_126. Consider increasing the input size. Received input shape [None, 1, 1, 33] which would produce output shape with a zero or negative value in a dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mglobal\u001b[39;00m prob_list_bo\n\u001b[0;32m      3\u001b[0m prob_list_bo \u001b[39m=\u001b[39m []\n\u001b[1;32m----> 4\u001b[0m result \u001b[39m=\u001b[39m gp_minimize(objective, search_space, n_calls\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m420\u001b[39;49m, acq_func\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgp_hedge\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      6\u001b[0m \u001b[39m# Print the best set of hyperparameters and the corresponding accuracy\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mBest hyperparameters: \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m.\u001b[39mx\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\active-ml\\lib\\site-packages\\skopt\\optimizer\\gp.py:259\u001b[0m, in \u001b[0;36mgp_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[39mif\u001b[39;00m base_estimator \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    255\u001b[0m     base_estimator \u001b[39m=\u001b[39m cook_estimator(\n\u001b[0;32m    256\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mGP\u001b[39m\u001b[39m\"\u001b[39m, space\u001b[39m=\u001b[39mspace, random_state\u001b[39m=\u001b[39mrng\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, np\u001b[39m.\u001b[39miinfo(np\u001b[39m.\u001b[39mint32)\u001b[39m.\u001b[39mmax),\n\u001b[0;32m    257\u001b[0m         noise\u001b[39m=\u001b[39mnoise)\n\u001b[1;32m--> 259\u001b[0m \u001b[39mreturn\u001b[39;00m base_minimize(\n\u001b[0;32m    260\u001b[0m     func, space, base_estimator\u001b[39m=\u001b[39;49mbase_estimator,\n\u001b[0;32m    261\u001b[0m     acq_func\u001b[39m=\u001b[39;49macq_func,\n\u001b[0;32m    262\u001b[0m     xi\u001b[39m=\u001b[39;49mxi, kappa\u001b[39m=\u001b[39;49mkappa, acq_optimizer\u001b[39m=\u001b[39;49macq_optimizer, n_calls\u001b[39m=\u001b[39;49mn_calls,\n\u001b[0;32m    263\u001b[0m     n_points\u001b[39m=\u001b[39;49mn_points, n_random_starts\u001b[39m=\u001b[39;49mn_random_starts,\n\u001b[0;32m    264\u001b[0m     n_initial_points\u001b[39m=\u001b[39;49mn_initial_points,\n\u001b[0;32m    265\u001b[0m     initial_point_generator\u001b[39m=\u001b[39;49minitial_point_generator,\n\u001b[0;32m    266\u001b[0m     n_restarts_optimizer\u001b[39m=\u001b[39;49mn_restarts_optimizer,\n\u001b[0;32m    267\u001b[0m     x0\u001b[39m=\u001b[39;49mx0, y0\u001b[39m=\u001b[39;49my0, random_state\u001b[39m=\u001b[39;49mrng, verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    268\u001b[0m     callback\u001b[39m=\u001b[39;49mcallback, n_jobs\u001b[39m=\u001b[39;49mn_jobs, model_queue_size\u001b[39m=\u001b[39;49mmodel_queue_size)\n",
      "File \u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\active-ml\\lib\\site-packages\\skopt\\optimizer\\base.py:299\u001b[0m, in \u001b[0;36mbase_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_calls):\n\u001b[0;32m    298\u001b[0m     next_x \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39mask()\n\u001b[1;32m--> 299\u001b[0m     next_y \u001b[39m=\u001b[39m func(next_x)\n\u001b[0;32m    300\u001b[0m     result \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39mtell(next_x, next_y)\n\u001b[0;32m    301\u001b[0m     result\u001b[39m.\u001b[39mspecs \u001b[39m=\u001b[39m specs\n",
      "File \u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\active-ml\\lib\\site-packages\\skopt\\utils.py:789\u001b[0m, in \u001b[0;36muse_named_args.<locals>.decorator.<locals>.wrapper\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    786\u001b[0m arg_dict \u001b[39m=\u001b[39m {dim\u001b[39m.\u001b[39mname: value \u001b[39mfor\u001b[39;00m dim, value \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(dimensions, x)}\n\u001b[0;32m    788\u001b[0m \u001b[39m# Call the wrapped objective function with the named arguments.\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m objective_value \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39marg_dict)\n\u001b[0;32m    791\u001b[0m \u001b[39mreturn\u001b[39;00m objective_value\n",
      "Cell \u001b[1;32mIn[49], line 7\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(**params)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39m@use_named_args\u001b[39m(search_space)\n\u001b[0;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mobjective\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[0;32m      6\u001b[0m     \u001b[39m# Create the model\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     model \u001b[39m=\u001b[39m create_model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m      9\u001b[0m     \u001b[39m# Fit the model to the training data\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     model\u001b[39m.\u001b[39mfit(X_train\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m, \u001b[39m1\u001b[39m), y_train, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[47], line 7\u001b[0m, in \u001b[0;36mcreate_model\u001b[1;34m(learning_rate, dropout_rate, num_filters, num_layers)\u001b[0m\n\u001b[0;32m      5\u001b[0m model\u001b[39m.\u001b[39madd(MaxPooling2D((\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m)))\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_layers):\n\u001b[1;32m----> 7\u001b[0m     model\u001b[39m.\u001b[39;49madd(Conv2D(num_filters, (\u001b[39m3\u001b[39;49m, \u001b[39m3\u001b[39;49m), activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m      8\u001b[0m     model\u001b[39m.\u001b[39madd(MaxPooling2D((\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m)))\n\u001b[0;32m      9\u001b[0m     model\u001b[39m.\u001b[39madd(Dropout(dropout_rate))\n",
      "File \u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\active-ml\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\active-ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\active-ml\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py:347\u001b[0m, in \u001b[0;36mConv.compute_output_shape\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mTensorShape(\n\u001b[0;32m    341\u001b[0m             input_shape[:batch_rank]\n\u001b[0;32m    342\u001b[0m             \u001b[39m+\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilters]\n\u001b[0;32m    343\u001b[0m             \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_spatial_output_shape(input_shape[batch_rank \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m :])\n\u001b[0;32m    344\u001b[0m         )\n\u001b[0;32m    346\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m--> 347\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    348\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOne of the dimensions in the output is <= 0 \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    349\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdue to downsampling in \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m. Consider \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    350\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mincreasing the input size. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    351\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived input shape \u001b[39m\u001b[39m{\u001b[39;00minput_shape\u001b[39m}\u001b[39;00m\u001b[39m which would produce \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    352\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39moutput shape with a zero or negative value in a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    353\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdimension.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    354\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: One of the dimensions in the output is <= 0 due to downsampling in conv2d_126. Consider increasing the input size. Received input shape [None, 1, 1, 33] which would produce output shape with a zero or negative value in a dimension."
     ]
    }
   ],
   "source": [
    "# Perform Bayesian optimization\n",
    "global prob_list_bo\n",
    "prob_list_bo = []\n",
    "result = gp_minimize(objective, search_space, n_calls=10, random_state=420, acq_func=\"gp_hedge\")\n",
    "\n",
    "# Print the best set of hyperparameters and the corresponding accuracy\n",
    "print(f'Best hyperparameters: {result.x}')\n",
    "print(f'Best accuracy: {1.0 - result.fun}')\n",
    "print(prob_list_bo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "active-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "5550561c7e85dace74674ee19323cd385967e1b9da6fedebe9016268a83c5703"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
